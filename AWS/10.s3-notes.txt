S3 (object store) stands for simple storage service
An object store (not a file system).
You can store files and "folders" but can't have locks, permissions etc like you would with a traditional file system

[Other option - 
EFS(Elastic file system), 
EBS(Elastic block store - Device like C:, D: only accessible through its EC2), 
Glacier - long term
[Note - If you provision a 100-GB EBS volume for a month, but only store 1 GB of data on that volume, you are still billed for 100 GB/m of EBS storage.]

---

Create Bucket, then put objects in it. Object can be image, pdf anything.
Bucket types:
       General purpose - commonly used for website hosting, backups, logs, and media storage.
       Directory - Optimized for workloads requiring hierarchical directory-like storage (e.g., data lakes, file-system-like structures).
                   For optimization, resides in single AZ.
Why Do They Appear the Same? (Directory vs General purpose)
Both buckets store objects (your JPG files).
You can upload, download, and view files in both buckets via the S3 console.
The basic object operations (GET, PUT, DELETE) work the same way.
Key Differences That Matter Over Time
To notice the real differences, try these actions:

1. Check Folder Structure & Listing Speed
In a General Purpose Bucket, S3 does not actually store directoriesâ€”it only simulates them using object prefixes.
In a Directory Bucket, S3 maintains a true hierarchical structure (like a file system), meaning directory-based queries (like listing files in a folder) are much faster.
2. Query with AWS Athena or AWS Glue
If you run Athena queries on a Directory Bucket, it will perform better and understand the hierarchy natively.
For a General Purpose Bucket, you would need to structure the prefixes carefully to optimize queries.


---
Decide what type of S3 you need based on how frequently you need data, how quick. Make it cost effective if data is
infrequently used by using storage like 
	S3 infrequent, 
	glacier, 
	zone IA. 
else use 
	standard frequent, 
	standard reduced redundancy - like pdf books in library 



Accessing S3 data
---------------
1. Using URL:http:s3.amazonaws.com/<BUCKET_NAME>/<OBJECT_NAME> - This will work only when url is publically accessible.
2. Programmatically - Can use boto library
		s3Client = boto3.client('s3')
		myobject = s3Client.get_object(Buket='BUCKET_NAME', Key='<OBJECT_NAME>')

 
Features
Lifecycle management
	Transition action - choose to move object to another storage class
	Expiration action - delete after certain amount of time

Bucket policy - IAM policy for ARN(Amazon resource name) access control
AWS recommends that you turn on Block all public access, but before applying any of these settings, ensure that your applications will work correctly without public access.
When we create a bucket, it needs to be associated with a region. Bucket name needs to be universally unique? Once deleted, it takes time to have that same name reused. While you are waiting, it becomes available, someone else(different account) can use the name. 

Data encryption at rest and transmission
	Client side for rest
	Server side for in motion

Versioning - Unintentional edits can be rolled back. Need to explicitly enable it.

Cross-Region Replication
	Pre-requisite
	 - version enabled in both source and destination
	 - Proper role assignment
	 Note : Data replication from one region to another will increase your expenses. Storing 1TB of data in a bucket, will cost you approximately $23 per month in the US-East region. - 4/27/2020

Transfer Acceleration
	e.g, 5 terrabyte to be moved from mumbai to oregon use cloud front
	
Q. How is S3 associated in VPC? Doesn't it need compute like EC2 to sit on?
A. S3 is a global service that is accessed over the internet, and it doesn't reside inside a VPC. By default,S3 buckets are region-specific. But you can do cross-region replication.

S3 is a fully managed object storage service offered by AWS. It doesn't require compute resources like EC2 instances to operate. AWS manages the infrastructure that S3 runs on.
--------
1 GB to store in US-East-1: (Updated at 2016.dec.20)

Glacier: $0.004/Month (Note: Major price cut in 2016)
S3: $0.023/Month
S3-IA (announced in 2015.09): $0.0125/Month (+$0.01/gig retrieval charge)
EBS: $0.045-0.1/Month (depends on speed - SSD or not) + IOPS costs
EFS: $0.3/Month

===========================
Question
1. Why is zonal replication of S3 bucket not made possible.
2. Which type of IAM policy would you use to grant access to a specific service action, like S3 bucket read access?

A. Identity-based policy
B. Resource-based policy
C. Organization policy
D. SCP (Service Control Policy)

Answer: A. Identity-based policy

# Default data consistency model for Amazon S3: mazon S3 offers strong read-after-write consistency for new objects. This means that immediately after a write request for a new object, you can retrieve it with a consistent read.
# Enable 'Object Lock' to prevent accidental deletion of objects
# Amazon S3 supports SSE-S3, SSE-KMS, and client-side encryption for encrypting data in transit and at rest
#  maximum individual object size that can be stored in Amazon S3: 5TB
# Amazon S3 achieves high availability by automatically replicating data across multiple availability zones within a region.




====================
Assignment
Create bucket and add objects(files). Restrict few objects access to a IAM user.
Add policy to S3 bucket or folder or object for auto deletion after 30 days.
